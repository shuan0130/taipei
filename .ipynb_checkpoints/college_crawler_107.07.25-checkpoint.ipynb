{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import threading\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_url = \"https://zh.wikipedia.org/wiki/%E8%87%BA%E5%8C%97%E5%B8%82%E5%A4%A7%E5%B0%88%E9%99%A2%E6%A0%A1%E5%88%97%E8%A1%A8\"\n",
    "col_resp = r.get(col_url)\n",
    "#print(col_resp.text)\n",
    "col_link = re.findall('<li><a href=\"(/wiki/.+?)\" .+?</a>', col_resp.text)\n",
    "#print(col_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "urlist_temp = \"https://zh.wikipedia.org{}\"\n",
    "col_urlist = []\n",
    "for i in range(len(col_link)):\n",
    "    col_urlist.append(urlist_temp.format(col_link[i]))\n",
    "# col_urlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colname = []\n",
    "for j in col_urlist:\n",
    "    content1 = r.get(j)\n",
    "    soup1 = BeautifulSoup(content1.text,\"lxml\")#取得col_urlist裡面所有網站的內文\n",
    "    if(soup1.find('th',{'class':'fn org'})):\n",
    "        colname.append(soup1.find('th',{'class':'fn org'}).text)\n",
    "    else:\n",
    "        colname.append(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coladdress = []\n",
    "for j in col_urlist:\n",
    "    content1 = r.get(j) #擷取每個網址\n",
    "    soup1 = BeautifulSoup(content1.text, \"lxml\") #擷取每個網址的html\n",
    "    if(soup1.find('td',{'class':'adr'})):\n",
    "        coladdress.append(soup1.find('td',{'class':'adr'}).text)\n",
    "    elif(soup1.find('td',{'class':'street-address'})):\n",
    "        coladdress.append(soup1.find('td',{'class':'street-address'}).text)\n",
    "    else:\n",
    "        coladdress.append(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colldic = {\n",
    "    '校名':colname,\n",
    "    '地址':coladdress\n",
    "}\n",
    "dfcollege = pd.DataFrame(colldic)\n",
    "dfcollegecl = dfcollege.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfcollegecl.T.iloc[1] = dfcollegecl.T.iloc[1].apply(lambda x: x.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcollegecl.to_csv(\"C:/Users/Big data/Education/college.csv\",index=False,encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
